{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17984184-9fd3-4b39-a546-87379f86e541",
   "metadata": {},
   "source": [
    "Cluster ordering function taken from Ishimoto 2018 Sci Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1eb01f-660b-486b-ab9d-2dd76d9cd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e47442e-545a-423e-a671-16de079d9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "BOX_SIZE = 500.0  # Must match the box size of the simulation\n",
    "DR = BOX_SIZE/100          # Bin width for distance (resolution)\n",
    "R_MAX = BOX_SIZE/4     # Max distance to calculate correlation for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e7d3b-b45b-4585-9369-0866ed660eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rdf_pbc(coords1, coords2, box_size, r_range):\n",
    "    \"\"\"\n",
    "    Computes the 2D Radial Distribution Function g(r) with Periodic Boundary Conditions.\n",
    "    \n",
    "    Args:\n",
    "        coords1: (N, 2) array of positions for reference particles (Type A)\n",
    "        coords2: (M, 2) array of positions for target particles (Type B)\n",
    "        box_size: Side length of the simulation box\n",
    "        r_range: Array of bin edges for distance\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Calculate vector differences (N x M x 2) using broadcasting\n",
    "    delta = coords1[:, np.newaxis, :] - coords2[np.newaxis, :, :]\n",
    "    \n",
    "    # 2. Apply Periodic Boundary Conditions (Minimum Image Convention)\n",
    "    delta = delta - box_size * np.round(delta / box_size)\n",
    "    \n",
    "    # 3. Calculate squared distances\n",
    "    dists_sq = np.sum(delta**2, axis=2)\n",
    "    dists = np.sqrt(dists_sq)\n",
    "    \n",
    "    # 4. Flatten\n",
    "    dists_flat = dists.flatten()\n",
    "    \n",
    "    # 5. Histogram counts\n",
    "    counts, bin_edges = np.histogram(dists_flat, bins=r_range)\n",
    "    \n",
    "    # 6. Normalization by Ideal Gas Density (Area of shells)\n",
    "    # Area of 2D shell = pi * (r_outer^2 - r_inner^2)\n",
    "    areas = np.pi * (r_range[1:]**2 - r_range[:-1]**2)\n",
    "    \n",
    "    # Global density of Type B\n",
    "    rho_2 = len(coords2) / (box_size**2)\n",
    "    \n",
    "    # Expected count if particles were randomly distributed\n",
    "    # N_ref * Density_target * Area_shell\n",
    "    expected_counts = len(coords1) * rho_2 * areas\n",
    "    \n",
    "    # Calculate g(r) avoiding divide by zero\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        g_r = counts / expected_counts\n",
    "        \n",
    "    # Get bin centers for plotting\n",
    "    r_centers = (r_range[:-1] + r_range[1:]) / 2\n",
    "    return r_centers, g_r\n",
    "\n",
    "def analyze_and_plot(filename, times_to_analyze):\n",
    "    \"\"\"Loads a parquet file, computes correlations, and plots them.\"\"\"\n",
    "    print(f\"--- Analyzing: {filename} ---\")\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    # Setup bins\n",
    "    r_bins = np.arange(0, R_MAX + DR, DR)\n",
    "    \n",
    "    # Prepare Plot\n",
    "    fig, axes = plt.subplots(1, len(times_to_analyze), figsize=(6 * len(times_to_analyze), 5), sharey=True)\n",
    "    if len(times_to_analyze) == 1: axes = [axes]\n",
    "    \n",
    "    for ax, t in zip(axes, times_to_analyze):\n",
    "        # Filter for closest time point\n",
    "        available_times = df['Time'].unique()\n",
    "        actual_t = available_times[np.argmin(np.abs(available_times - t))]\n",
    "        df_t = df[df['Time'] == actual_t]\n",
    "        \n",
    "        # Extract positions\n",
    "        pos_motile = df_t[df_t['Type'] == 'motile'][['Pos_X', 'Pos_Y']].values\n",
    "        pos_sub = df_t[df_t['Type'] == 'submotile'][['Pos_X', 'Pos_Y']].values\n",
    "        pos_all = df_t[['Pos_X', 'Pos_Y']].values\n",
    "\n",
    "        # --- A. All-to-All Correlation ---\n",
    "        # Useful for homogeneous simulations\n",
    "        if len(pos_all) > 0:\n",
    "            r, g = compute_rdf_pbc(pos_all, pos_all, BOX_SIZE, r_bins, exclude_self=True)\n",
    "            ax.plot(r, g, label='All Particles', color='black', alpha=0.5, linestyle='--')\n",
    "\n",
    "        # --- B. Specific Correlations (for Heterogeneous) ---\n",
    "        # 1. Motile-Motile\n",
    "        if len(pos_motile) > 10:\n",
    "            r, g = compute_rdf_pbc(pos_motile, pos_motile, BOX_SIZE, r_bins, exclude_self=True)\n",
    "            ax.plot(r, g, label='Motile-Motile', color='C0')\n",
    "            \n",
    "        # 2. Submotile-Submotile\n",
    "        if len(pos_sub) > 10:\n",
    "            r, g = compute_rdf_pbc(pos_sub, pos_sub, BOX_SIZE, r_bins, exclude_self=True)\n",
    "            ax.plot(r, g, label='Sub-Sub', color='C1')\n",
    "            \n",
    "        # 3. Motile-Submotile (Cross Correlation)\n",
    "        if len(pos_motile) > 0 and len(pos_sub) > 0:\n",
    "            r, g = compute_rdf_pbc(pos_motile, pos_sub, BOX_SIZE, r_bins, exclude_self=False)\n",
    "            ax.plot(r, g, label='Motile-Sub', color='purple')\n",
    "\n",
    "        ax.set_title(f\"Time $\\\\approx$ {actual_t}\")\n",
    "        ax.set_xlabel(\"Distance $r$\")\n",
    "        ax.set_ylabel(\"$g(r)$\")\n",
    "        ax.axhline(1.0, color='gray', linestyle=':', alpha=0.5) # Reference line\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "        \n",
    "    plt.suptitle(f\"File: {filename}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution Loop ---\n",
    "# This grabs all parquet files generated by your previous script\n",
    "simulation_files = glob.glob(\"*.parquet\")\n",
    "simulation_files.sort()\n",
    "\n",
    "# Choose specific time points to check (e.g., Early, Middle, Late)\n",
    "# Adjust these based on your simulation length\n",
    "time_points = [10.0, 50.0, 100.0] \n",
    "\n",
    "if not simulation_files:\n",
    "    print(\"No parquet files found! Make sure to run the simulation first.\")\n",
    "else:\n",
    "    for f in simulation_files:\n",
    "        analyze_and_plot(f, time_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
